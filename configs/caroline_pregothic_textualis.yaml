defaults:
  - training: defaults
  - model: defaults
  - dataset: iwcp
  - _self_

hydra:
  run:
    dir: .
  output_subdir: null
  verbose: False

tag: iwcp
dataset:
  iwcp:
    supervised: True

model:
  encoder:
    H: 96

  background:

    init:
      constant: [0.5, 0.5, 0.5]    

  loss:
    ctc_factor: 0.01

training:
  n_workers: 8
  batch_size: 16
  num_epochs: 200
  optimizer:
    lr: 1.0e-4
  
  log_every: 
    milestone: 1

# python train.py caroline_pregothic_textualis.yaml training.optimizer.lr=1.0e-4 model.loss.ctc_factor=0.001 tag=iwcp-0.01-4