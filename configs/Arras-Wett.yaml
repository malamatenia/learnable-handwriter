defaults:
  - training: defaults
  - model: defaults
  - dataset: cremma_masks
  - _self_

hydra:
  run:
    dir: .
  output_subdir: null
  verbose: False

tag: Arras-Wett

dataset:
  cremma_masks:
    supervised: True
    starts_with: ['Arras','Wett']

model:
  encoder:
    H: 96

  sprites:
    init:
      color:
        freeze: 300

  transformation: #for the curriculum_learning
    layer:
      ops: ['color', 'position'] #'identity'
      #curriculum_learning: [300, 300]

  background:
    init:
      constant: [0.50, 0.50, 0.50] 
      #[0.7372549019607844, 0.7254901960784313, 0.6588235294117647]

  loss:
    ctc_factor: 0.01

training:
  n_workers: 8
  batch_size: 16
  num_epochs: 500
  optimizer:
    lr: 1.0e-4
  
log:
  milestone: 1

#python train.py Arras-Wett.yaml training.optimizer.lr=1.0e-3 model.loss.ctc_factor=0.1 tag=Arras-Wett-masks-0.1-3
